import os
import numpy as np
import pandas as pd
from sentence_transformers import SentenceTransformer
import torch

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import TruncatedSVD
from sklearn.preprocessing import Normalizer
from sklearn.neighbors import NearestNeighbors

# ------------------------
# 0) ì„¤ì •
# ------------------------
CSV_IN   = os.getenv("CSV_IN", "OS_Matrics[ED].csv")
MODEL_ID = os.getenv("MODEL_ID", "KIPI-ai/KorPatElectra")
HF_TOKEN = os.getenv("HF_TOKEN")  # ë°˜ë“œì‹œ í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •í•  ê²ƒ

assert HF_TOKEN is not None, "í™˜ê²½ë³€ìˆ˜ HF_TOKENì„ ì„¤ì •í•˜ì„¸ìš” (export HF_TOKEN=...)"

# ------------------------
# 1) ë°ì´í„° ë¡œë“œ (ë‹¨ì¼ ì»¬ëŸ¼ ê·œê²©í™”)
# ------------------------
df = pd.read_csv(CSV_IN)
df = df.reset_index(drop=True)
TEXT_COLUMN = 'ìš”ì•½' if 'ìš”ì•½' in df.columns else df.columns[0]
texts = df[TEXT_COLUMN].fillna("").astype(str).tolist()

# ------------------------
# 2) KorPatElectra ì„ë² ë”©
# ------------------------
device = "cuda" if torch.cuda.is_available() else "cpu"
model = SentenceTransformer(MODEL_ID, use_auth_token=HF_TOKEN).to(device)
X_kpe = model.encode(texts, batch_size=128, show_progress_bar=True, device=device)

# ------------------------
# 3) LSA ì„ë² ë”© (TF-IDF â†’ SVD â†’ Normalizer, ì¿¼ë¦¬ì—ë„ ë™ì¼ ë³€í™˜ ì ìš©)
# ------------------------
tfidf = TfidfVectorizer(max_df=0.8, min_df=5, ngram_range=(1, 2))
X_tfidf = tfidf.fit_transform(texts)

n_terms = X_tfidf.shape[1]
n_comp = min(768, n_terms - 1) if n_terms > 1 else 1
svd = TruncatedSVD(n_components=n_comp, random_state=42)
X_lsa_raw = svd.fit_transform(X_tfidf)
normalizer = Normalizer(copy=False)
X_lsa = normalizer.fit_transform(X_lsa_raw)  # ë¬¸ì„œ ì •ê·œí™”

# ------------------------
# 4) ì¿¼ë¦¬ì™€ ì •ë‹µ ì„¸íŠ¸
# ------------------------
query_texts = [
    "ë”¥ëŸ¬ë‹ì„ ì´ìš©í•œ ê³ í•´ìƒë„ ì´ë¯¸ì§€ ìƒì„± ë°©ë²•",     # ì´ë¯¸ì§€ ìƒì„±
    "í…ìŠ¤íŠ¸ ìƒì„±ì„ ìœ„í•œ ì–¸ì–´ ëª¨ë¸ì„ ìƒì„±í•˜ê¸° ìœ„í•œ ë°©ë²•"  # í…ìŠ¤íŠ¸ ìƒì„±
]
ground_truth = {
    0: [27, 76, 744, 880, 871, 1076, 1890, 1692, 383, 991, 1994],
    1: [489, 1621, 1972, 744, 763, 888, 1074, 1751, 1798],
}
# ìœ íš¨ ì¸ë±ìŠ¤ í•„í„° (ground truthê°€ df ê¸¸ì´ ì´ˆê³¼í•˜ëŠ” ê²½ìš° ëŒ€ë¹„)
N = len(df)
ground_truth = {qi: [idx for idx in idxs if 0 <= idx < N] for qi, idxs in ground_truth.items()}

# ------------------------
# 5) ì¿¼ë¦¬ ì„ë² ë”© (KPE/LSA ëª¨ë‘ ì½”í¼ìŠ¤ íŒŒì´í”„ë¼ì¸ê³¼ ë™ì¼ ì²˜ë¦¬)
# ------------------------
# KPE
query_emb_kpe = model.encode(query_texts, batch_size=8, device=device)
query_emb_kpe = l2norm(query_emb_kpe)

# LSA
query_tfidf = tfidf.transform(query_texts)      # fit() ê¸ˆì§€, ë°˜ë“œì‹œ transform()
query_lsa_raw = svd.transform(query_tfidf)      # ì½”í¼ìŠ¤ì— ë§ì¶° í•™ìŠµëœ SVD ì‚¬ìš©
query_emb_lsa = normalizer.transform(query_lsa_raw)

# ------------------------
# 6) í‰ê°€ í•¨ìˆ˜ (NearestNeighborsë¡œ Top-kë§Œ)
# ------------------------
def evaluate_queries_knn(query_emb, doc_emb, ground_truth, model_name="Model", k=10):
    nbrs = NearestNeighbors(n_neighbors=min(k, len(doc_emb)), metric='cosine')
    nbrs.fit(doc_emb)

    Pk_list, Rk_list, MRRk_list = [], [], []
    per_query = []

    for qi in range(len(query_emb)):
        true_set = set(ground_truth.get(qi, []))
        if not true_set:
            continue

        distances, indices = nbrs.kneighbors(query_emb[qi:qi+1], return_distance=True)
        topk_idx = indices[0].tolist()

        hits = [1 if idx in true_set else 0 for idx in topk_idx]
        Pk = sum(hits) / len(topk_idx)
        Rk = sum(hits) / max(1, len(true_set))

        # MRR@k
        mrr = 0.0
        for rank, h in enumerate(hits, start=1):
            if h == 1:
                mrr = 1.0 / rank
                break

        Pk_list.append(Pk)
        Rk_list.append(Rk)
        MRRk_list.append(mrr)
        per_query.append((qi, Pk, Rk, mrr, topk_idx))

    print(f"\nğŸ“Œ [{model_name}] Query-based Evaluation (Top-{len(topk_idx)})")
    print(f"Precision@k: {np.mean(Pk_list):.4f}")
    print(f"Recall@k:    {np.mean(Rk_list):.4f}")
    print(f"MRR@k:       {np.mean(MRRk_list):.4f}")

    # ê° ì¿¼ë¦¬ë³„ ìƒì„¸
    for qi, Pk, Rk, mrr, idxs in per_query:
        print(f"  - Q{qi}: P@k={Pk:.3f}, R@k={Rk:.3f}, MRR@k={mrr:.3f}, topk_head={idxs[:5]}")

# ------------------------
# 7) ì‹¤í–‰
# ------------------------
evaluate_queries_knn(query_emb_kpe, X_kpe, ground_truth, model_name="KorPatElectra", k=10)
evaluate_queries_knn(query_emb_lsa, X_lsa, ground_truth, model_name="LSA",           k=10)
